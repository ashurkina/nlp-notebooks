{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2097c2cc-a5c1-4c94-ae21-6d9ce83b8340",
   "metadata": {},
   "source": [
    "# Installing the libraries\n",
    "\n",
    "- spaCy: https://spacy.io/[link text](https://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa01ae8a-46a8-46cc-bd86-aeda6148eb4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/4c/d9/439aed2e686b30aef877dea6181852810ae9dc2fcbc9003e9eedb543e463/spacy-3.8.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading spacy-3.8.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/d3/f4/0208624de330224f3a8981c030007fc4a3583ca6b4d4dd3275364c1d06e6/murmurhash-1.0.12-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/03/e3/d98e3976f4ffa99cddebc1ce379d4d62e3eb1da22285267f902c99cc3395/cymem-2.0.11-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading cymem-2.0.11-cp311-cp311-macosx_10_9_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/c0/1e/05fa559f53b635d96b233b63e93accb75215025b997486f7290991bec6c3/preshed-3.0.9-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.4.0,>=8.3.4 from https://files.pythonhosted.org/packages/85/47/68187c78a04cdc31cbd3ae393068f994b60476b5ecac6dfe7d04b124aacf/thinc-8.3.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading thinc-8.3.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/df/9c/a248bb49de499fe0990e3cb0fb341c2373d8863ef9a8b5799353cade5731/srsly-2.5.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading srsly-2.5.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.5.0,>=0.1.0 from https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Obtaining dependency information for typer<1.0.0,>=0.3.0 from https://files.pythonhosted.org/packages/d0/cc/0a838ba5ca64dc832aa43f727bd586309846b0ffb2ce52422543e6075e8a/typer-0.15.1-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Obtaining dependency information for tqdm<5.0.0,>=4.38.0 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Obtaining dependency information for numpy>=1.19.0 from https://files.pythonhosted.org/packages/21/67/32c68756eed84df181c06528ff57e09138f893c4653448c4967311e0f992/numpy-2.2.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading numpy-2.2.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/f4/3c/8cc1cc84deffa6e25d2d0c688ebb80635dfdbf1dbea3e30c541c8cf4d860/pydantic-2.10.6-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/c3/6b/068c2ea7a712bf805c62445bd9e9c06d7340358ef2824150eceac027444b/langcodes-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/5d/e9/5a5ffd9b286db82be70d677d0a91e4d58f7912bb8dd026ddeeb4abe70679/language_data-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Obtaining dependency information for pydantic-core==2.27.2 from https://files.pythonhosted.org/packages/c2/89/f3450af9d09d44eea1f2c369f49e8f181d742f28220f88cc4dfaae91ea6e/pydantic_core-2.27.2-cp311-cp311-macosx_10_12_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-macosx_10_12_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Obtaining dependency information for blis<1.3.0,>=1.2.0 from https://files.pythonhosted.org/packages/3c/3f/62bc963d7cad6d5d4038ca0fed236559abd67c1afca33a2d5644412470f7/blis-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading blis-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for click>=8.0.0 from https://files.pythonhosted.org/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/1f/6e/b64600156934dab14cc8b403095a9ea8bd722aad2e775673c68346b76220/cloudpathlib-0.20.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for smart-open<8.0.0,>=5.2.1 from https://files.pythonhosted.org/packages/7a/18/9a8d9f01957aa1f8bbc5676d54c2e33102d247e146c1a3679d3bd5cc2e3a/smart_open-7.1.0-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for marisa-trie>=1.1.0 from https://files.pythonhosted.org/packages/6d/1d/5c36500ac350c278c9bdfd88e17fa846fa4136d75597c167141ed973cdf2/marisa_trie-1.2.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/50/ff/149aba8365fdacef52b31a258c4dc1c57c79759c335eff0b3316a2664a64/wrapt-1.17.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading spacy-3.8.4-cp311-cp311-macosx_10_9_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-macosx_10_9_x86_64.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.12-cp311-cp311-macosx_10_9_x86_64.whl (26 kB)\n",
      "Downloading numpy-2.2.2-cp311-cp311-macosx_10_9_x86_64.whl (21.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.2/21.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading preshed-3.0.9-cp311-cp311-macosx_10_9_x86_64.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.0/133.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-macosx_10_9_x86_64.whl (635 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.9/635.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-macosx_10_9_x86_64.whl (839 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m839.3/839.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-macosx_10_9_x86_64.whl (192 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-macosx_10_9_x86_64.whl (38 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, tqdm, spacy-loggers, spacy-legacy, shellingham, pydantic-core, numpy, murmurhash, mdurl, marisa-trie, cloudpathlib, click, catalogue, annotated-types, srsly, smart-open, pydantic, preshed, markdown-it-py, language-data, blis, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "Successfully installed annotated-types-0.7.0 blis-1.2.0 catalogue-2.0.10 click-8.1.8 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.12 numpy-2.2.2 preshed-3.0.9 pydantic-2.10.6 pydantic-core-2.27.2 rich-13.9.4 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 tqdm-4.67.1 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290bcaec-74c1-4cbd-9277-98976255ea67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5d2cc-738b-4f1d-ba17-f492dfe326a9",
   "metadata": {},
   "source": [
    "Download a package to work with (choose language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca81431f-a16e-43b2-b089-f9165dc8b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5951a1-fa53-45d1-bfbb-833095bf51bb",
   "metadata": {},
   "source": [
    "# POS (part-of-speech)\n",
    "POS (part-of-speech): <br>\n",
    "* noun\n",
    "* adjective\n",
    "* verb\n",
    "\n",
    "It is important to find named entities: tags <br><br>\n",
    "\n",
    "## Legend\n",
    "* lemma: \"root\" of the word\n",
    "* pos: part-of-speech\n",
    "* tag: morphological information (present, future, past)\n",
    "* dep: syntatic dependency\n",
    "* shape: lowercase, uppercase\n",
    "* alpha: if it is alphanumeric\n",
    "* stop: if it is a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0648097b-af2c-4811-9f25-fdd146a9f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "badbb2a5-0f18-4084-b705-f82ad04e6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd50c20-fd1e-4b02-ab31-5350f11e2f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x10e641fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ecf7be-32a9-4345-9727-b451fa8c2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = nlp(\"I am learning NLP. The course is in London.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9bfdb20-7c3f-4177-b268-b3f942351fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "am AUX\n",
      "learning VERB\n",
      "NLP PROPN\n",
      ". PUNCT\n",
      "The DET\n",
      "course NOUN\n",
      "is AUX\n",
      "in ADP\n",
      "London PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in document:\n",
    "  print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e8552a-5a3a-4f48-8a52-423ad3de29b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON I PRP nsubj X True True\n",
      "am AUX be VBP aux xx True True\n",
      "learning VERB learn VBG ROOT xxxx True False\n",
      "NLP PROPN NLP NNP dobj XXX True False\n",
      ". PUNCT . . punct . False False\n",
      "The DET the DT det Xxx True True\n",
      "course NOUN course NN nsubj xxxx True False\n",
      "is AUX be VBZ ROOT xx True True\n",
      "in ADP in IN prep xx True True\n",
      "London PROPN London NNP pobj Xxxxx True False\n",
      ". PUNCT . . punct . False False\n"
     ]
    }
   ],
   "source": [
    "for token in document:\n",
    "  print(token.text, token.pos_, token.lemma_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b6d06c-dd2b-4387-9a4c-e12db53bc27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\n",
      "London\n"
     ]
    }
   ],
   "source": [
    "for token in document:\n",
    "  if token.pos_ == \"PROPN\":\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c87cbcb-3f76-4159-aa6d-a925eabbb000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n"
     ]
    }
   ],
   "source": [
    "for token in document:\n",
    "  if token.pos_ == \"VERB\":\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0d83d-1b96-4486-8011-1a9aa249821c",
   "metadata": {},
   "source": [
    "# Lemmatization and stemming\n",
    "\n",
    "*   Lemmatization: meaning of the word based on the dictionary (morphological analysis) - extract the base word\n",
    "*   Stemming: extract the root of the word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35ae829-11e2-423d-9fb9-daf8e685b0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I\n",
      "am be\n",
      "learning learn\n",
      "NLP NLP\n",
      ". .\n",
      "The the\n",
      "course course\n",
      "is be\n",
      "in in\n",
      "London London\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for token in document:\n",
    "  print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39af163-1041-425e-b003-e89f808d5562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learn', 'learning', 'learn', 'learn', 'watch', 'watching', 'watch']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization is useful for reducing dimentionality of the data instead of storing 3 words we store 1 word\n",
    "\n",
    "doc = nlp(\"learn learning learned learns watch watching watched\")\n",
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01c06a28-c963-4272-8f3f-6b1f692c56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from nltk) (8.1.8)\n",
      "Collecting joblib (from nltk)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/34/4c/8f8e631fcdc2ff978609eaeef1d6994bf2f028b59d9ac67640ed051f1218/regex-2024.11.6-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading regex-2024.11.6-cp311-cp311-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m999.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: tqdm in /Users/marinaashurkina/code/nlp-notebooks/env/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-macosx_10_9_x86_64.whl (287 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.7/287.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.4.2 nltk-3.9.1 regex-2024.11.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7446ef58-a745-4462-8206-a8ed51785735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PorterStemmer is a name of algorithm\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "stemmer.stem(\"watching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ca76b32-27c0-4028-a9f1-2c5ee62c89a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I i\n",
      "am be am\n",
      "learning learn learn\n",
      "NLP NLP nlp\n",
      ". . .\n",
      "The the the\n",
      "course course cours\n",
      "is be is\n",
      "in in in\n",
      "London London london\n",
      ". . .\n"
     ]
    }
   ],
   "source": [
    "for token in document:\n",
    "  print(token.text, token.lemma_, stemmer.stem(token.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ae614-b0e7-4ee3-a97a-50cf18bfcee6",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "The idea of this technique is to find and classify entities in text such as people locations money and so on. Can be used in chatbots.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1aaff97-9aa1-41ab-8690-eaebed875bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'IBM is a US compay on information technology. It is located in San Francisco and revenue in 2018 was approximately 320 billion dollars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "578fea16-8710-4965-bbc2-38f5d5f96c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "553da015-e696-4b38-900c-dc023f3163ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM ORG\n",
      "US GPE\n",
      "San Francisco GPE\n",
      "2018 DATE\n",
      "approximately 320 billion dollars MONEY\n"
     ]
    }
   ],
   "source": [
    "for entity in document.ents:\n",
    "  print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e873fad-b866-4d37-9784-a92f52f3bd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    IBM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is a \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " compay on information technology. It is located in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and revenue in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2018\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " was \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    approximately 320 billion dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(document, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61d0d955-3ee8-4e53-b8db-965645d43a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Bill Gates was born in Seattle on 1955-10-28 and is the founder of Microsoft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e27669b-da69-4355-aa8a-76c186016899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill Gates PERSON\n",
      "Seattle GPE\n",
      "1955-10-28 DATE\n",
      "Microsoft ORG\n"
     ]
    }
   ],
   "source": [
    "document = nlp(text)\n",
    "for entity in document.ents:\n",
    "  print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7fe42a0-df97-4376-9f95-76a0537e1f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bill Gates\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was born in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Seattle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1955-10-28\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and is the founder of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(document, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b750d2d-194c-445a-8616-dfa39748df33",
   "metadata": {},
   "source": [
    "# Stop Words\n",
    "* Words that appear very often and don't help to understand the context of the document. Can be used in sentiment analysis tasks: for example word 'it' is a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae3c0d91-a012-4e0a-bfad-e8660c672808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'soi-même', 'pourquoi', 'je', 'quarante', 'directement', 'quatrièmement', 'auxquels', 'cent', 'procedant', 'sous', 'néanmoins', 'ô', 'dire', 'quant-à-soi', 'tenant', 'notre', 'semblable', 'la', 'mienne', 'hem', 'votre', 'desormais', 'precisement', 'afin', 'basee', \"d'\", 'deuxième', 'avais', 'spécifique', 'hou', 'dits', 'doit', 'relative', 'moi-meme', 'onze', 'mon', 'doivent', 'quatrième', 'j’', 'hui', 'celles-ci', 'troisième', 'cela', 'sixième', 'ouverte', 'hi', 'mes', 'ceux-ci', 'dixième', 'diverse', \"quelqu'un\", 'car', 'suivantes', 'parmi', 'vas', 'restent', 'retour', 'egalement', 'nôtres', 'façon', 'miennes', 'semblaient', 'siens', 'cinquante', 'puis', 'ainsi', 'parler', 'celui', 'da', 'diverses', 'voici', \"qu'\", 'premier', 'sienne', 'suit', 'huitième', 'effet', 'souvent', 'tres', 'hue', 'revoilà', 'malgré', 'suis', 'tel', 'devra', 'neanmoins', 'touchant', 'quand', 'est', 'malgre', 'chaque', 'pourrait', 'tente', 'tes', 'celui-ci', 'combien', 'relativement', 'avaient', 'douzième', 'miens', 'autres', 'chez', 'trois', 'moins', 'unes', 'tend', 'soit', 'ceux-là', 'également', 'hep', 'faisaient', 'i', 'quelle', 'tous', 'sur', 'ai', 'té', 'pour', 'cette', 'tout', 'celui-la', 'lors', 'rendre', 'leurs', 'sa', 'celle-là', 'differentes', 'siennes', 'ouias', 'excepté', 'vôtre', 'tiens', 'anterieures', 'nôtre', 'quiconque', 'septième', 'peut', 'aux', 'ouvert', 'tien', 'seulement', 'précisement', 'celles', 't’', 'assez', 'eu', \"j'\", 'parfois', 'ho', 'pu', 'proche', 'parce', 'lui-même', 'aie', 'differents', 'seule', 'ta', 'douze', 'elles-memes', 'importe', 'maint', 'lorsque', 'dix-sept', 'plutôt', 'troisièmement', 'vers', 'deux', 'â', 'sont', 'etais', 'lesquels', 'vé', 'à', 'certaines', 'ces', 'pres', 'celles-là', 'déjà', 'auxquelles', 'son', 'avait', 'où', 'quelque', 'c’', 'antérieur', 'moi-même', 'ah', 'ont', 'nombreuses', 'les', 'toujours', 'pas', 'mais', 'différents', 'etant', 'que', 'sait', 'tellement', 'étais', 'avec', 'concernant', 'directe', 'longtemps', 'm’', 'votres', 'quant', 'laisser', 'ne', 'un', 'stop', 'jusqu', 'devant', 'hors', 'houp', 'dessus', 'auquel', 'avons', 'celui-là', 'notamment', 'hé', 'en', 'me', 'tenir', 'ce', 'sien', 'nous-mêmes', 'bat', 'ça', 'seront', 'qu’', 'suivant', 'quoique', 'treize', 'vu', 'après', 'te', 'suffisante', 'ha', 'vous-mêmes', 'y', 'celle-ci', 'très', 'exactement', 'tienne', 'encore', 'on', 'aupres', 'elle-même', 'fais', 'certaine', 'sept', 'cependant', \"s'\", 'lequel', 'autre', 'de', 'dedans', 'déja', 'apres', 'alors', 'ait', 'allons', 'telle', 'deuxièmement', 'ma', 'revoila', 'ton', 'des', 'dix', 'elle-meme', 'elles-mêmes', 'aussi', 'mille', 'ayant', 'quels', 'enfin', 'suivants', 'comment', 'soixante', 'six', 'voila', 'l’', 'le', 'cinquantaine', 'permet', 'quelques', \"t'\", 'ouverts', 'possibles', 'première', 'dont', 'voilà', 'dès', 'même', 'plusieurs', 'specifique', 'nos', 'abord', 'es', 'n’', 'plus', 'telles', 'lesquelles', 's’', 'sans', 'peux', 'va', 'sera', 'dite', 'différente', 'uns', 'puisque', 'leur', 'par', 'parle', 'revoici', 'quatre-vingt', 'soi', 'serait', 'et', 'ceci', 'hormis', 'semble', 'etc', 'etait', 'ni', 'cinq', 'gens', 'toi-même', 'fait', 'quatre', 'au', 'via', 'certes', 'chacune', 'juste', 'lui', 'premièrement', 'donc', 'moi', 'nous', 'celles-la', 'suffisant', 'different', 'neuvième', 'specifiques', 'suivante', 'étaient', 'ils', 'o', 'dix-neuf', 'facon', 'auraient', 'pendant', 'plutot', 'celle', 'sent', 'antérieures', 'outre', 'seraient', 'onzième', 'sauf', 'd’', 'du', \"c'\", 'anterieure', 'certains', 'rend', 'antérieure', 'tant', 'debout', 'lui-meme', 'maintenant', 'partant', 'nombreux', 'quelconque', 'suivre', 'avoir', 'mien', 'vous', 'soi-meme', 'depuis', 'restant', 'ès', 'bas', 'aura', 'selon', 'elle', 'pense', 'toute', 'etaient', 'se', 'mêmes', 'aurait', 'peuvent', 'feront', 'autrui', 'sinon', 'duquel', \"l'\", 'environ', 'memes', 'vont', 'allaient', 'semblent', 'trente', 'seules', 'toi-meme', 'ceux', 'vingt', 'quoi', 'ses', 'derrière', 'parlent', 'eux-mêmes', 'etre', 'dit', 'auront', 'toi', 'tiennes', 'étant', 'dessous', 'vais', 'durant', 'cinquantième', 'possible', 'spécifiques', 'différent', 'differente', 'attendu', 'eux', 'ou', 'surtout', 'desquelles', 'entre', 'était', 'dix-huit', 'une', 'divers', 'huit', 'pouvait', 'ouste', 'elles', 'a', 'or', 'certain', 'cinquième', 'envers', 'suffit', 'seuls', 'prealable', 'vôtres', 'devers', 'quatorze', 'personne', 'avant', 'meme', 'eh', 'comme', 'compris', 'dans', 'reste', 'anterieur', 'peu', 'autrement', 'quel', 'laquelle', 'qui', 'désormais', 'quelles', 'il', 'être', \"m'\", 'derriere', 'là', 'tels', 'nul', 'delà', 'merci', 'as', 'font', 'nouveau', 'préalable', 'quinze', 'différentes', 'moindres', 'tu', 'dejà', 'si', 'cet', 'celle-la', 'jusque', 'toutes', 'près', 'pourrais', 'faisant', 'seize', 'lès', 'na', 'dehors', 'vos', 'chacun', 'seul', 'desquels', 'ci', \"n'\", 'deja'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a502a6b1-b33b-4b8c-8db3-a65830a135b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whereupon', 'thus', 'third', 'he', 'somehow', '’d', 'ever', 'us', 'anyway', 'still', 'then', 'now', 'neither', 'everywhere', 'seemed', 'nor', 'some', 'for', 'from', 'onto', 'made', 'could', 'through', 'throughout', 'each', 'many', 'become', 'even', 'therein', 'used', '‘m', 'twenty', 'yourselves', 'hers', 'using', 'seems', 'move', 'too', 'within', 'mostly', 'you', 'anything', 'once', 'are', 'hence', 'more', 'take', 'own', 'most', 'an', \"'m\", 'we', '‘ve', 'name', 'her', 'never', 'by', 'least', 'herself', 'ten', 'empty', 'must', 'behind', 'no', 'during', 'done', 'just', 'beyond', 'say', 'all', 'unless', 'among', 'which', 'until', 'both', 'had', 'have', 'nowhere', 'same', 'often', 'i', \"'ve\", 'eight', 'though', 'go', 'nothing', 'am', 'them', 'being', 'does', 'thence', 'over', 'can', 'latterly', 'yet', 'upon', 'another', 'regarding', 'make', 'fifteen', 'otherwise', 'along', 'keep', 'hereupon', 'whereafter', 'bottom', 'its', 'formerly', 'sixty', 'call', 'and', 'noone', 'nevertheless', 'either', 'serious', 'above', 'former', 'others', '‘ll', 'per', 'while', 'except', 'down', 'whole', 'wherever', 'last', 'at', 'due', 'before', 'anyhow', 'whoever', 'his', 'toward', 'other', 'be', 'much', 'quite', 'amount', 'part', 'three', 'latter', 'mine', 're', 'me', 'will', 'across', 'wherein', 'these', 'to', 'on', 'do', 'first', 'front', 'also', 'myself', 'anyone', 'put', 'against', 'than', 'ours', 'whereas', '’ll', 'well', 'may', 'my', 'back', 'with', 'nine', 'cannot', 'because', 'six', 'those', 'whatever', 'themselves', 'eleven', 'around', 'nobody', 'moreover', 'yours', 'when', 'is', 'itself', 'sometimes', '‘d', 'side', 'below', 'did', 'fifty', 'two', 'together', 'but', '’m', 'sometime', 'give', 'in', 'off', 'almost', 'our', 'without', 'very', 'who', 'between', 'elsewhere', 'if', 'thereby', 'therefore', 'whereby', 'here', 'since', 'less', 'seem', \"'re\", 'via', 'would', 'namely', 'such', 'was', 'became', 'yourself', 'four', 'five', 'although', 'becomes', 'please', 'thru', 'been', 'whither', 'whom', 'always', 'already', 'somewhere', 'after', 'else', 'ourselves', 'again', 'how', '‘re', 'him', 'their', 'might', 'alone', 'n‘t', 'various', 'thereupon', 'someone', 'see', 'indeed', 'what', 'hereby', 'thereafter', 'were', 'hundred', 'everything', 'meanwhile', 'towards', 'something', 'show', 'really', 'whence', 'beside', 'out', 'any', 'they', 'get', '’ve', 'it', 'amongst', 'hereafter', 'twelve', 'into', 'forty', \"n't\", 'this', 'himself', 'besides', 'doing', 'a', 'or', 'why', 'further', 'has', 'afterwards', 'few', 'every', 'enough', 'herein', 'the', 'becoming', 'where', 'several', '’s', 'top', 'everyone', 'whether', 'seeming', 'she', \"'s\", 'under', 'your', 'only', '’re', 'as', 'rather', 'about', 'whose', 'one', 'whenever', 'none', 'not', 'n’t', 'should', 'next', '‘s', 'so', 'anywhere', 'full', 'however', \"'ll\", 'there', 'ca', 'of', \"'d\", 'perhaps', 'beforehand', 'that', 'up'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87bdf1ac-a442-4916-9e67-a4542196467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'it' in STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65c53ed5-92e8-4c02-9272-8f96b594fbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2e2b380-6717-4d23-8bc1-d5b25594484c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['it'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3534f40a-7241-4aac-a566-95b6c657e84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['computer'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db0a9a2e-1c63-4b80-b12f-b32c41f24fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "NLP\n",
      ".\n",
      "course\n",
      "London\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "document = nlp(\"I am learning NLP. The course is in London.\")\n",
    "for token in document:\n",
    "  if not nlp.vocab[token.text].is_stop:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe70f4-8c84-4940-a1be-0fbbc4c72740",
   "metadata": {},
   "source": [
    "# Dependency Parsing\n",
    "\n",
    "Identifying relations between the words.*italicized text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8562cf4-97ff-429f-b60b-b06dba03fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". course\n"
     ]
    }
   ],
   "source": [
    "origin = document[4]\n",
    "destination = document[6]\n",
    "print(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34be2fb2-b858-4b53-8b47-b7105a67271e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[learning]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(origin.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ffa9317-c713-4075-9cae-8995da0637fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[is]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(destination.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d928d77-6dd4-4f85-90a0-53ee6fd045c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[0].is_ancestor(document[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75252a05-6be8-4c59-82bb-9b0da4628c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = nlp(\"Book a table for the restaurant and a taxi to the hotel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10862487-ac43-4d49-95c9-87572c3836a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(table, taxi) (restaurant, hotel)\n"
     ]
    }
   ],
   "source": [
    "tasks = document[2], document[8]\n",
    "locations = document[5], document[11]\n",
    "print(tasks, locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ae34703-9083-4b6f-bbeb-886b8808377a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95eaa94f-f44c-43f4-9cf1-d51528bfa872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- restaurant\n",
      "for\n",
      "table\n",
      "Book\n",
      "---- hotel\n",
      "to\n",
      "taxi\n",
      "restaurant\n",
      "for\n",
      "table\n",
      "Book\n"
     ]
    }
   ],
   "source": [
    "for local in locations:\n",
    "  print('----', local)\n",
    "  for obj in local.ancestors:\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65786819-6789-474c-a466-ebed1f0458dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reservations of table to the restaurant\n",
      "Reservations of taxi to the hotel\n"
     ]
    }
   ],
   "source": [
    "for local in locations:\n",
    "  for obj in local.ancestors:\n",
    "    if obj in tasks:\n",
    "      print(\"Reservations of {} to the {}\".format(obj, local))\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63c9fd36-7964-4c90-8b07-c493fa07d324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[the, and, taxi]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(document[5].children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b7bef-2770-4133-acb1-81c19e0c78f1",
   "metadata": {},
   "source": [
    "## Visualizing the dependencies between the *words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10795690-eda8-4c7f-9a0d-8136163cfd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69cdb52b-c058-4980-8ccf-2ec11319ed80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"93c7258709214294a5791838848ad54f-0\" class=\"displacy\" width=\"2150\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Book</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">table</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">restaurant</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">taxi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">hotel</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-0\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-1\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,179.0 L408.0,167.0 392.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,179.0 L1103.0,167.0 1087.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-6\" stroke-width=\"2px\" d=\"M1295,177.0 C1295,89.5 1445.0,89.5 1445.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,179.0 L1287,167.0 1303,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-7\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1450.0,2.0 1450.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,179.0 L1458.0,167.0 1442.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-8\" stroke-width=\"2px\" d=\"M1470,177.0 C1470,89.5 1620.0,89.5 1620.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1620.0,179.0 L1628.0,167.0 1612.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-9\" stroke-width=\"2px\" d=\"M1820,177.0 C1820,89.5 1970.0,89.5 1970.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,179.0 L1812,167.0 1828,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-93c7258709214294a5791838848ad54f-0-10\" stroke-width=\"2px\" d=\"M1645,177.0 C1645,2.0 1975.0,2.0 1975.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-93c7258709214294a5791838848ad54f-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1975.0,179.0 L1983.0,167.0 1967.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document = nlp(\"Book a table for the restaurant and a taxi to the hotel\")\n",
    "displacy.render(document, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43949360-f480-4fcd-b39e-64cd87340dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Book]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(document[2].ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9846142e-22b4-4892-b157-e2e743901158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[a, for]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(document[2].children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84d2bd85-8604-470c-8a46-e9f1b0ec986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(London, Paris) (visit, stay)\n"
     ]
    }
   ],
   "source": [
    "document = nlp(\"What places can we visit in London and stay in Paris?\")\n",
    "locations = document[6], document[10]\n",
    "actions = document[4], document[8]\n",
    "print(locations, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdca8729-40a6-460d-adcc-464b218c9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London to visit\n",
      "Paris to stay\n"
     ]
    }
   ],
   "source": [
    "for local in locations:\n",
    "  #print(local)\n",
    "  for action in local.ancestors:\n",
    "    if action in actions:\n",
    "      print('{} to {}'.format(local, action))\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7104d887-a168-4824-991b-2e347e317cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b611ecfd6ca040e1bd044fefdb6252f9-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">What</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">places</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">can</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">we</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">visit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">London</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">stay</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">Paris?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,2.0 410.0,2.0 410.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,47.0 405.0,47.0 405.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,139.0 L332,127.0 348,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-4\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M490.0,139.0 L498.0,127.0 482.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-5\" stroke-width=\"2px\" d=\"M520,137.0 C520,92.0 580.0,92.0 580.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M580.0,139.0 L588.0,127.0 572.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-6\" stroke-width=\"2px\" d=\"M430,137.0 C430,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M675.0,139.0 L683.0,127.0 667.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-7\" stroke-width=\"2px\" d=\"M430,137.0 C430,2.0 770.0,2.0 770.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,139.0 L778.0,127.0 762.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-8\" stroke-width=\"2px\" d=\"M790,137.0 C790,92.0 850.0,92.0 850.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M850.0,139.0 L858.0,127.0 842.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-9\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b611ecfd6ca040e1bd044fefdb6252f9-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M940.0,139.0 L948.0,127.0 932.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(document, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e3f4d-0b21-4859-aca3-7e09061d2b7e",
   "metadata": {},
   "source": [
    "# Word Similarity\n",
    "\n",
    "Calculation of similarity between words and sentences <br>\n",
    "\n",
    "GloVe algorithms: global vectors for Word Representation <br>\n",
    "\n",
    "Can be used to track inconsistent words;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9193b-a2d6-41b1-838c-9689898d359d",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "678b87fe-ea2f-4de8-84f7-40de04580e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/jdfwqb9x39l895f9wvgxsx9w0000gn/T/ipykernel_10545/2652363994.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  w1.similarity(w2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7422727346420288"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating similarity\n",
    "\n",
    "w1 =nlp('cat')\n",
    "w2 = nlp('dog')\n",
    "w3 = nlp('monkey')\n",
    "\n",
    "w1.similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7064531f-bd29-4c5c-8a8d-de87cd1ecf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/jdfwqb9x39l895f9wvgxsx9w0000gn/T/ipykernel_10545/3046747863.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  w1.similarity(w3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5400806069374084"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.similarity(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9255477-9933-4af0-b78b-1f28fa757f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = nlp(\"When will the new movie be released?\")\n",
    "text2 = nlp(\"What is the new movie?\")\n",
    "text3 = nlp(\"What color is the car?\")\n",
    "text4 = nlp(\"What is the color of the car?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e397c392-a6fd-49d7-b629-f4d0b55f4c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/jdfwqb9x39l895f9wvgxsx9w0000gn/T/ipykernel_10545/3951576355.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  text1.similarity(text2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41953960061073303"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.similarity(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21a6d38e-83d7-4e60-ab21-046e90eb70c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/jdfwqb9x39l895f9wvgxsx9w0000gn/T/ipykernel_10545/1842271901.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  text1.similarity(text3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42811474204063416"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.similarity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e53b9b91-9627-42dd-9227-0b6b3b7e5734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/jdfwqb9x39l895f9wvgxsx9w0000gn/T/ipykernel_10545/1006816930.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  text3.similarity(text4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8015265464782715"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.similarity(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad89341-2c6a-4e9e-bc85-87c31d4fd908",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa78775b-b0b8-40f1-8ab0-700076ab16b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- cat\n",
      "cat is 100.0% similar to cat\n",
      "cat is 64.98286724090576% similar to dog\n",
      "cat is 58.25124979019165% similar to horse\n",
      "cat is 21.207033097743988% similar to person\n",
      "---- dog\n",
      "dog is 64.98286724090576% similar to cat\n",
      "dog is 100.0% similar to dog\n",
      "dog is 63.53861689567566% similar to horse\n",
      "dog is 25.16682744026184% similar to person\n",
      "---- horse\n",
      "horse is 58.25124979019165% similar to cat\n",
      "horse is 63.53861689567566% similar to dog\n",
      "horse is 100.0% similar to horse\n",
      "horse is 17.508962750434875% similar to person\n",
      "---- person\n",
      "person is 21.207033097743988% similar to cat\n",
      "person is 25.16682744026184% similar to dog\n",
      "person is 17.508962750434875% similar to horse\n",
      "person is 100.0% similar to person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/jdfwqb9x39l895f9wvgxsx9w0000gn/T/ipykernel_10545/316654310.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = text1.similarity(text2) *100\n"
     ]
    }
   ],
   "source": [
    "text = nlp(\"cat dog horse person\")\n",
    "for text1 in text:\n",
    "  print('----', text1)\n",
    "  for text2 in text:\n",
    "    #print(text2)\n",
    "    similarity = text1.similarity(text2) *100\n",
    "    print('{} is {}% similar to {}'.format(text1, similarity, text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd00fdbc-c7fa-4caa-bbb7-00fb7f7112ec",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "we call one word as a token and we can extract some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31a1c61d-7ab1-44d8-90bb-bee0f4bdfb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "learning\n",
      "NLP\n",
      ".\n",
      "The\n",
      "course\n",
      "is\n",
      "in\n",
      "London\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "document1 = nlp(\"I am learning NLP. The course is in London.\")\n",
    "\n",
    "for token in document1:\n",
    "  print(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29aa114f-62cd-4863-ac54-0c6de32c239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'learning', 'NLP.', 'The', 'course', 'is', 'in', 'London.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document2 = \"I am learning NLP. The course is in London.\"\n",
    "document2.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c7d6aa-ead6-414f-8df1-8a83b1f0a848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
